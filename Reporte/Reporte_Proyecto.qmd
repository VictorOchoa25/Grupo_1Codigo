---
title: "Análisis Predictivo del Rendimiento Académico Estudiantil"
subtitle: "Identificación de Factores Clave y Modelos Predictivos para el Éxito Estudiantil"
author: "Salvador y Víctor"
date: today
format:
  html:
    theme: flatly
    toc: true        # activa el índice
    toc-depth: 3     # niveles de encabezados
    toc-location: left   # barra lateral
    # opcional:
    # number-sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.align = "center",
  fig.pos = "H",
  out.width = "90%"
)
library(knitr)
library(kableExtra)
library(ggplot2)
library(tidyverse)      # Manipulación y visualización de datos
library(skimr)          # Resúmenes estadísticos
library(corrplot)       # Matrices de correlación
library(patchwork)      # Composición de gráficos
```

# Introducción

El conjunto de datos [*Student Performance*](https://doi.org/10.24432/C5TG7T) contiene información detallada sobre el rendimiento académico de estudiantes de secundaria en la asignatura de Matemáticas, junto con una amplia gama de variables demográficas, sociales, familiares y conductuales. Los datos fueron recopilados mediante encuestas en dos escuelas secundarias públicas de Portugal y están disponibles en el repositorio UCI Machine Learning.

Basados en la descripción del respositorio, el rendimiento académico de los estudiantes no depende únicamente de su capacidad cognitiva, sino que está fuertemente influenciado por factores contextuales como el entorno familiar, los hábitos de estudio, el apoyo escolar, las relaciones sociales y las condiciones socioeconómicas. En este contexto, identificar tempranamente a los estudiantes en riesgo de reprobación permite a las instituciones educativas implementar estrategias de intervención oportuna, optimizando recursos y promoviendo la equidad en el aprendizaje. Por ello, es crucial desarrollar modelos predictivos que, a partir de variables observables al inicio del curso, puedan anticipar el resultado académico final.

El conjunto de datos incluye 395 observaciones y 33 variables, entre las que se encuentran:

-   **Demográficas**: edad, género, tipo de residencia (urbana o rural).

-   **Familiares**: nivel educativo de los padres, ocupación, tipo de tutor, calidad de las relaciones familiares.

-   **Académicas**: número de ausencias, fracasos previos, apoyo escolar extra, acceso a internet.

-   **De comportamiento**: tiempo de estudio, frecuencia de salidas con amigos, consumo de alcohol, tiempo libre.

-   **De desempeño**: calificaciones en el primer (G1), segundo (G2) y tercer período (G3).

En este proyecto de **clasificación binaria**; el objetivo es detectar si un estudiante aprobará o reprobará, transformando la variable objetivo continua (G3) en una variable categórica binaria. Así, en lugar de predecir la calificación exacta, se define la variable respuesta **Pass** como:

$$
\texttt{Pass} =\begin{cases}\text{yes}, & \text{si } \texttt{G3} \geq 10 \\\text{no}, & \text{si } \texttt{G3} < 10\end{cases}
$$

Este umbral (10 sobre 20) corresponde al criterio tradicional de aprobación en el sistema educativo portugués . Es importante destacar que, para preservar la validez de la predicción temprana, las calificaciones intermedias (G1 y G2) se excluyen del conjunto de predictores, evitando así cualquier fuga de información y asegurando que el modelo se base únicamente en factores observables antes del cierre del curso.

# Business understanding

Planteamos algunas preguntas sobre nuestros datos:

-   ¿Un mayor nivel educativo de los padres se asocia con una mayor probabilidad de aprobación?
-   ¿El número de fracasos previos es el predictor más fuerte de reprobación?
-   ¿El apoyo escolar extra mejora significativamente las probabilidades de aprobación?
-   ¿Una mayor frecuencia de salidas con amigos se asocia con menor rendimiento?

# Compresión de los datos.

## Descripción del Conjunto de Datos

El proyecto utiliza el conjunto de datos de Rendimiento Estudiantil que contiene 395 estudiantes con 33 atributos que describen variable de tipo: demografía, contexto social y registros académicos.

```{r load-data}

library(tidyverse)
library(janitor) # Para limpiar y estandarizar nombres de columnas
library(knitr)   # Para generar tablas limpias (kable)
library(skimr)   # Para generar resúmenes estadísticos rápidos
# 1. Cargar el dataset usando read_csv2 para el delimitador punto y coma (;)

data_raw <- read_csv2("Data/studentmat.csv")

# 2. Limpiar los nombres de las columnas (ej: de "G1" a "g1")
data <- data_raw %>%
  clean_names()


```

```{r dict-demographic}
dict_demographic <- tibble(
  Variable = c("school", "sex", "age", "address"),
  Tipo = c("Categórica", "Categórica", "Numérica", "Categórica"),
  Valores = c("GP, MS", "F, M", "15-22", "U, R"),
  Descripción = c(
    "Escuela del estudiante (GP: Gabriel Pereira, MS: Mousinho da Silveira)",
    "Sexo del estudiante (F: Femenino, M: Masculino)",
    "Edad del estudiante en años",
    "Tipo de domicilio del estudiante (U: Urbano, R: Rural)"
  )
)

dict_demographic %>%
  kable(caption = "Variables Demográficas")
```

```{r dict-family}
dict_family <- tibble(
  Variable = c("famsize", "Pstatus", "Medu", "Fedu", "Mjob", "Fjob", "guardian"),
  Tipo = c("Categórica", "Categórica", "Ordinal", "Ordinal", "Categórica", "Categórica", "Categórica"),
  Valores = c("LE3, GT3", "T, A", "0-4", "0-4", "teacher, health, services, at_home, other", 
              "teacher, health, services, at_home, other", "mother, father, other"),
  Descripción = c(
    "Tamaño de la familia (LE3: ≤3 miembros, GT3: >3 miembros)",
    "Estado de convivencia de los padres (T: Juntos, A: Separados)",
    "Nivel educativo de la madre (0: ninguna, 1: primaria, 2: 5-9 grado, 3: secundaria, 4: superior)",
    "Nivel educativo del padre (0: ninguna, 1: primaria, 2: 5-9 grado, 3: secundaria, 4: superior)",
    "Trabajo de la madre",
    "Trabajo del padre",
    "Tutor legal del estudiante"
  )
)

dict_family %>%
  kable(caption = "Variables Familiares")
```

```{r dict-school}
dict_school <- tibble(
  Variable = c("reason", "traveltime", "studytime", "failures", "schoolsup", 
               "famsup", "paid", "activities", "nursery", "higher", "absences"),
  Tipo = c("Categórica", "Ordinal", "Ordinal", "Numérica", "Categórica", 
           "Categórica", "Categórica", "Categórica", "Categórica", "Categórica", "Numérica"),
  Valores = c("home, reputation, course, other", "1-4", "1-4", "0-4", "yes, no", 
              "yes, no", "yes, no", "yes, no", "yes, no", "yes, no", "0-93"),
  Descripción = c(
    "Razón para elegir esta escuela",
    "Tiempo de viaje casa-escuela (1: <15min, 2: 15-30min, 3: 30min-1h, 4: >1h)",
    "Tiempo de estudio semanal (1: <2h, 2: 2-5h, 3: 5-10h, 4: >10h)",
    "Número de fallos académicos previos",
    "Recibe apoyo educativo extra de la escuela",
    "Recibe apoyo educativo de la familia",
    "Toma clases extra pagadas en matemáticas",
    "Participa en actividades extracurriculares",
    "Asistió a guardería",
    "Desea seguir educación superior",
    "Número de ausencias escolares"
  )
)

dict_school %>%
  kable(caption = "Variables Escolares")
```

```{r dict-social}
dict_social <- tibble(
  Variable = c("internet", "romantic", "famrel", "freetime", "goout", 
               "Dalc", "Walc", "health"),
  Tipo = c("Categórica", "Categórica", "Ordinal", "Ordinal", "Ordinal", 
           "Ordinal", "Ordinal", "Ordinal"),
  Valores = c("yes, no", "yes, no", "1-5", "1-5", "1-5", "1-5", "1-5", "1-5"),
  Descripción = c(
    "Tiene acceso a internet en casa",
    "Está en una relación romántica",
    "Calidad de relaciones familiares (1: muy mala - 5: excelente)",
    "Tiempo libre después de la escuela (1: muy bajo - 5: muy alto)",
    "Frecuencia de salidas con amigos (1: muy baja - 5: muy alta)",
    "Consumo de alcohol entre semana (1: muy bajo - 5: muy alto)",
    "Consumo de alcohol en fin de semana (1: muy bajo - 5: muy alto)",
    "Estado de salud actual (1: muy malo - 5: muy bueno)"
  )
)

dict_social %>%
  kable(caption = "Variables Sociales y de Salud")
```

```{r head-data}
head(data, 10) %>% 
  kable(caption = "Primeras 10 observaciones del dataset")


data_summary <- data %>% skim()
data_summary

```

Este conjunto de datos contiene información sobre 395 estudiantes, sin valores faltantes. Incluye 33 variables que describen aspectos personales, familiares, sociales y académicos. Hay 17 variables categóricas, como el género, la escuela o el motivo para elegir esta, y 16 numéricas, como edad, tiempo de estudio, número de ausencias y calificaciones en los tres periodos (g1, g2, g3). Todos los datos están completos, lo que permite un análisis confiable del rendimiento académico y los factores asociados.

# Análisis Exploratorio de Datos (EDA)

```{r}
#| label: setup-eda
#| include: false
#| message: false
library(tidyverse)
library(knitr)
library(corrplot) # Para visualizar la matriz de correlación
library(patchwork) # Para organizar gráficos
```

### Análisis Univariado de la Variable Objetivo ($\text{G3}$)

```{r}
#| label: g3-distribution
#| echo: false
#| message: false
#| fig-width: 8
#| fig-height: 4

g3_stats <- data %>%
  summarise(
    Media = mean(g3),
    Mediana = median(g3),
    Min = min(g3),
    Max = max(g3)
  )

# Histograma de G3
data %>%
  ggplot(aes(x = g3)) +
  geom_histogram(binwidth = 1, fill = "darkred", color = "white", alpha = 0.8) +
  geom_vline(aes(xintercept = g3_stats$Media), color = "blue", linetype = "dashed", size = 1) +
  labs(title = "Distribución de la Nota Final (G3)",
       x = "Nota Final (G3)",
       y = "Frecuencia") +
  theme_minimal()

cat("\n### Estadísticas Descriptivas de G3\n")
g3_stats %>%
  kable(caption = "Estadísticas clave de la Nota Final (G3).", digits = 2, format = "html")
```

La distribución de la nota final (\$\\text{G3}\$) presenta un sesgo negativo (hacia la izquierda), ya que la Mediana (11) es ligeramente superior a la Media (10.42), aunque ambos valores son cercanos. El rango completo de notas es utilizado, yendo de \$\\text{0}\$ (nota mínima) a \$\\text{20}\$ (nota máxima). La presencia de una alta frecuencia de notas cero sugiere un número significativo de reprobados o no presentados.

### Análisis Bivariado: Factores Numéricos vs. $\text{G3}$

```{r}
#| label: correlation-matrix
#| echo: false
#| message: false
#| fig-width: 9
#| fig-height: 9

# Seleccionar solo las variables numéricas que serán predictoras
num_predictors <- data %>% 
  select(g3, age, medu, fedu, traveltime, studytime, failures, famrel, freetime, goout, dalc, walc, health, absences)

# Calcular la matriz de correlación de Pearson
cor_matrix <- cor(num_predictors)

cat("### Matriz de Correlación de Factores Numéricos y G3\n")

# Gráfico de la matriz de correlación
corrplot(cor_matrix, 
         method = "circle", 
         type = "lower", 
         diag = FALSE,
         title = "Correlación entre G3 y Factores Numéricos",
         mar=c(0,0,1,0)) # Ajustar márgenes para el título
```

-   Las correlaciones más fuertes y negativas se encuentran con **`failures`** (-0.37) y **`age`** (-0.23). Los estudiantes con más fallas previas y de mayor edad tienden a tener notas $\text{G3}$ más bajas.

<!-- -->

-   Existe una correlación positiva con la **`medu`** (Educación de la Madre, 0.22) y **`fedu`** (Educación del Padre, 0.17).

### Relaciones Gráficas de Factores Clave vs. $\text{G3}$

```{r}
#| label: key-numerical-vs-g3
#| echo: false
#| message: false
#| fig-width: 12
#| fig-height: 4

# Failures vs G3 (Boxplot ya que failures es discreta)
plot_failures <- data %>%
  mutate(failures_cat = factor(failures, levels = 0:4, labels = c("0", "1", "2", "3", ">3"))) %>%
  ggplot(aes(x = failures_cat, y = g3)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "G3 vs. Fallas Previas", x = "Número de Fallas", y = "G3") +
  theme_minimal()

# Studytime vs G3 (Boxplot)
plot_studytime <- data %>%
  mutate(studytime_cat = factor(studytime)) %>%
  ggplot(aes(x = studytime_cat, y = g3)) +
  geom_boxplot(fill = "lightgreen") +
  labs(title = "G3 vs. Tiempo de Estudio", x = "Tiempo (1 a 4)", y = "G3") +
  theme_minimal()

# Absences vs G3 (Scatter con línea de tendencia)
plot_absences <- data %>%
  ggplot(aes(x = absences, y = g3)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(title = "G3 vs. Ausencias", x = "Número de Ausencias", y = "G3") +
  theme_minimal()

# Mostrar los tres gráficos
plot_failures + plot_studytime + plot_absences
```

-   **Fallas Previas (`failures`):** Existe una **relación negativa muy fuerte**. A medida que el número de fallas previas aumenta (de 0 a $>3$), la **mediana de** $\text{G3}$ cae drásticamente, validando que el historial académico es un predictor que puede ser muy útil.

<!-- -->

-   **Tiempo de Estudio (`studytime`):** La relación es **positiva**. Los estudiantes que dedican más tiempo a estudiar semanalmente (niveles 2, 3 y 4) muestran consistentemente una **mediana de** $\text{G3}$ superior a aquellos que estudian menos de 2 horas (nivel 1).

-   **Ausencias (`absences`):** El gráfico de dispersión muestra una **correlación muy débil** con $\text{G3}$, ya que la línea de tendencia es casi plana, lo que sugiere que el número de ausencias por sí solo no es un predictor lineal fuerte de la nota final para la mayoría de los estudiantes.

### Análisis Bivariado: Factores Categóricos vs. $\text{G3}$

```{r}
#| label: key-categorical-vs-g3
#| echo: false
#| message: false
#| fig-width: 12
#| fig-height: 4

# Función para crear Boxplots de Categorías vs G3
plot_category_vs_g3 <- function(data, variable, title, x_lab) {
  data %>%
    ggplot(aes(x = as.factor(.data[[variable]]), y = g3, fill = as.factor(.data[[variable]]))) +
    geom_boxplot(show.legend = FALSE) +
    labs(title = title, x = x_lab, y = "G3 (Nota Final)") +
    theme_minimal()
}

# Sexo vs G3
plot_sex <- plot_category_vs_g3(data, "sex", "G3 vs Sexo", "Sexo (F/M)")

# Deseo de Educación Superior (higher) vs G3
plot_higher <- plot_category_vs_g3(data, "higher", "G3 vs Deseo de Ed. Superior", "¿Desea estudiar?")

# Apoyo de la Familia (famsup) vs G3
plot_famsup <- plot_category_vs_g3(data, "famsup", "G3 vs Apoyo Familiar", "¿Apoyo Fam?")

# Mostrar los tres gráficos
plot_sex + plot_higher + plot_famsup
```

-   **Deseo de Educación Superior (`higher`):** Esta es la variable categórica **más influyente**. Los estudiantes que expresan un deseo de seguir estudios superiores (**"yes"**) tienen una **mediana de** $\text{G3}$ significativamente más alta (alrededor de 12) que aquellos que no lo desean, lo que puede indicar la importancia de la **motivación** como predictor.

<!-- -->

-   **Sexo (`sex`):** Existe una **diferencia sutil pero verificable** en el rendimiento. Los estudiantes varones (**M**) registran una **mediana de** $\text{G3}$ superior (11.00) a la de las estudiantes mujeres (**F**, 10.00).

-   **Apoyo Familiar (`famsup`):** El impacto de contar con apoyo familiar es **mínimo**. La diferencia en la mediana de $\text{G3}$ entre los grupos es **casi nula**, lo que indica que es probable que esta variable sea un predictor débil para el modelado.

### Respuesta preliminar a las preguntas de Business understanding

```{r}
#| label: conclusion-table-final-clean-v2
#| echo: false
#| message: false

library(knitr)
library(dplyr)
library(tibble)
library(kableExtra)

# 1. Crear el data frame con la información (SOLO TEXTO SIMPLE)
analisis_negocio_df_final <- tribble(
  ~Pregunta_Negocio, ~Variables_Clave, ~Analisis_Datos, ~Conclusion_Preliminar,
  "¿Un mayor nivel educativo de los padres se asocia con una mayor probabilidad de aprobación?", 
  "G3 vs. Medu y Fedu", 
  "Correlación positiva y moderada con G3 (Medu: 0.22, Fedu: 0.17).", 
  "Sí. Hay una asociación positiva. El nivel educativo de los padres se correlaciona con un mayor rendimiento.",
  
  "¿El número de fracasos previos es el predictor más fuerte de reprobación?", 
  "G3 vs. failures", 
  "Correlación más fuerte y negativa de todos los factores (-0.37). Caída drástica de la mediana de G3.", 
  "Sí. failures es el predictor de bajo rendimiento más potente entre los factores asociados.",
  
  "¿El apoyo escolar extra mejora significativamente las probabilidades de aprobación?", 
  "G3 vs. schoolsup", 
  "Mediana de G3 para estudiantes con apoyo (9.0) es inferior a la de sin apoyo (11.0).", 
  "Inconcluso. schoolsup es un indicador de riesgo, lo que sugiere que identifica a estudiantes con bajo rendimiento inicial.",
  
  "¿Una mayor frecuencia de salidas con amigos se asocia con menor rendimiento?", 
  "G3 vs. goout", 
  "Correlación negativa, pero débil (-0.13). Tendencia a la baja en G3 con más salidas.", 
  "Sí, existe una asociación negativa, pero su impacto es menor que otros factores, como failures o higher."
)

# 2. Renderizar la tabla usando kable con un estilo HTML atractivo
analisis_negocio_df_final %>%
  knitr::kable(
    caption = "Resumen de las Conclusiones Preliminares del EDA frente a las Preguntas de Negocio",
    col.names = c("Pregunta de Negocio", "Variables Clave", "Análisis del EDA", "Conclusión Preliminar"),
    format = "html"
  ) %>%
  # Añadir estilos de tabla generales
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = T,
    font_size = 11
  ) %>%
  # Resaltar las filas de conclusión fuerte (1 y 2) con colores suaves
  row_spec(1, color = "black", background = "#E6F3FF") %>% 
  row_spec(2, color = "black", background = "#FFE6E6") 
```

# Modelado

1.  Introducción y Configuración

Este reporte consolida el análisis de cuatro casos de estudio distintos para predecir el estatus de aprobación/reprobación de los estudiantes. El objetivo es determinar el impacto de la selección de variables y el balanceo de clases en el rendimiento del modelo.

Casos a Evaluar:

Caso 1: Todas las Variables / Sin Balanceo.

Caso 2: Todas las Variables / Con Balanceo (SMOTE).

Caso 3: Variables Seleccionadas / Sin Balanceo.

Caso 4: Variables Seleccionadas / Con Balanceo (SMOTE - Modelo Optimizado).

```{r}

# Cargar Librerías
if (!require(tidyverse)) install.packages("tidyverse")
if (!require(caret)) install.packages("caret")
if (!require(pROC)) install.packages("pROC")
if (!require(randomForest)) install.packages("randomForest")
if (!require(gbm)) install.packages("gbm")
if (!require(kernlab)) install.packages("kernlab")
if (!require(e1071)) install.packages("e1071")
if (!require(MASS)) install.packages("MASS")
if (!require(klaR)) install.packages("klaR")
if (!require(naivebayes)) install.packages("naivebayes")
if (!require(kableExtra)) install.packages("kableExtra")
if (!require(themis)) install.packages("themis") # Requerido para SMOTE en caret

library(tidyverse); library(caret); library(pROC); library(randomForest)
library(gbm); library(kernlab); library(e1071); library(MASS)
library(klaR); library(naivebayes); library(kableExtra); library(themis)

```

2.  Carga y Preparación de Datos

Se carga el conjunto de datos y se aplica el preprocesamiento estándar: conversión de tipos y eliminación de variables de notas intermedias (G1, G2) para evitar la filtración de información.

```{r}
# Cargar Datos (Ruta Robusta)
filename <- "Data/studentmat.csv"
if (!file.exists(filename)) filename <- "studentmat.csv"
if (!file.exists(filename)) stop("Error: studentmat.csv no encontrado.")

df_raw <- read.csv(filename, sep = ";", stringsAsFactors = FALSE)

# Conversiones Numéricas
numeric_cols <- c("age", "absences", "G3", "Medu", "Fedu", "traveltime", 
                  "studytime", "failures", "famrel", "freetime", "goout", 
                  "Dalc", "Walc", "health")

for(col in numeric_cols) {
  if(col %in% names(df_raw)) {
    df_raw[[col]] <- as.numeric(df_raw[[col]])
  }
}

# Creación del Objetivo
df_class <- df_raw %>%
  mutate(Status = ifelse(G3 >= 10, "Pass", "Fail")) %>%
  mutate(Status = as.factor(Status)) %>%
  dplyr::select(-G1, -G2, -G3) %>% 
  mutate(across(where(is.character), as.factor))

# Partición Global (75% Train / 25% Validation)
set.seed(123)
trainIndex <- createDataPartition(df_class$Status, p = 0.75, list = FALSE)
train_global <- df_class[trainIndex, ]
valid_global <- df_class[-trainIndex, ]

# Definición de Variables Seleccionadas (para Casos 3 y 4)
sel_vars <- c("failures", "absences", "higher", "age", "Medu", "goout", "guardian", "Status")
```

Proceso de Selección de Variables

Antes de proceder con el modelado, se emplearon tres métodos complementarios para identificar las variables más predictivas y reducir la dimensionalidad del problema.

Metodología de Selección

Pruebas Chi-Cuadrado: Para evaluar la dependencia entre variables categóricas y el estatus de aprobación.

Algoritmo Boruta: Para determinar la importancia de todas las variables frente a un atributo sombra aleatorio.

Eliminación Recursiva de Características (RFE): Para encontrar el subconjunto óptimo de variables que maximiza la precisión.

1.  Pruebas Chi-Cuadrado (Variables Categóricas)

A continuación, se ejecuta el código para calcular el valor P de Chi-Cuadrado para cada variable categórica frente a la variable objetivo Status.

```{r}
# --- CÓDIGO R: CHI-CUADRADO ---
cat_vars <- names(train_global)[sapply(train_global, is.factor)]
chi_df <- data.frame(Variable=character(), P_Value=numeric(), stringsAsFactors=FALSE)

for (v in cat_vars) {
  if (v != "Status") {
    test <- chisq.test(table(train_global[[v]], train_global$Status))
    chi_df <- rbind(chi_df, data.frame(Variable=v, P_Value=test$p.value))
  }
}
chi_df <- chi_df[order(chi_df$P_Value),]

# Mostrar resultados
kable(head(chi_df, 10), caption = "Top 10 Variables por Chi-Cuadrado", 
      align = c('l', 'r'), booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)

```

2.  Algoritmo Boruta (Importancia de Todas las Variables)

Se ejecuta el algoritmo Boruta para confirmar qué variables son estadísticamente más relevantes que el azar.

```{r}

if (!require(Boruta)) install.packages("Boruta")
library(Boruta)

# --- CÓDIGO R: BORUTA ---
set.seed(123)
# Ejecutamos Boruta en el set de entrenamiento
boruta_out <- Boruta(Status ~ ., data = train_global, doTrace = 0)

# Graficar resultados
plot(boruta_out, cex.axis=.6, las=2, xlab="", main="Importancia de Variables (Boruta)")

# Mostrar tabla de decisiones
boruta_decisions <- attStats(boruta_out)
boruta_decisions$Variable <- rownames(boruta_decisions)
# Filtramos solo las confirmadas para mostrar
confirmed_vars <- boruta_decisions[boruta_decisions$decision == "Confirmed", c("Variable", "meanImp", "decision")]

kable(confirmed_vars, caption = "Variables Confirmadas por Boruta", 
      align = c('l', 'r', 'c'), booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)

```

3.  Eliminación Recursiva de Características (RFE)

Finalmente, se utiliza RFE con un modelo Random Forest como base para encontrar el número óptimo de variables.

```{r}
# --- CÓDIGO R: RFE ---
set.seed(123)
ctrl_rfe <- rfeControl(functions = rfFuncs, method = "cv", number = 5)

# Ejecutamos RFE
rfe_out <- rfe(train_global[, names(train_global) != "Status"], 
               train_global$Status, 
               sizes = c(1:15), 
               rfeControl = ctrl_rfe)

# Mostrar resultados principales
print(rfe_out)
plot(rfe_out, type=c("g", "o"))

```

Conjunto Final de Variables Seleccionadas

Basado en el consenso de los tres métodos anteriores, se seleccionaron las siguientes 7 variables clave para los Casos 3 y 4.

```{r}
variables_finales <- data.frame(
  Variable = c("failures", "absences", "higher", "age", "Medu", "goout", "guardian"),
  Descripcion = c(
    "Número de fallas académicas previas",
    "Número total de ausencias",
    "Intención de cursar educación superior",
    "Edad del estudiante",
    "Nivel educativo de la madre",
    "Frecuencia de salidas sociales",
    "Persona responsable del estudiante"
  ),
  Metodos_Seleccion = c("3/3", "3/3", "2/3", "2/3", "2/3", "2/3", "2/3"),
  Justificacion = c(
    "Predictor más fuerte en todos los análisis",
    "Alta correlación con rendimiento académico",
    "Fuertemente relacionada con motivación estudiantil",
    "Indicador potencial de repetición de grado",
    "Factor socioeconómico importante",
    "Indicador de balance vida-estudio",
    "Indicador de estructura de apoyo familiar"
  )
)

kable(variables_finales, caption = "Conjunto Final de 7 Variables Seleccionadas", 
      align = c('l', 'l', 'c', 'l'), booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
```

3.  Ejecución de los Casos de Estudio

A continuación, se ejecutan los cuatro casos secuencialmente.

Función de Entrenamiento Genérica

Para asegurar que todos los modelos se ejecuten en todos los casos, definimos una función que entrena una lista estándar de algoritmos.

```{r}
train_and_evaluate_all <- function(train_data, valid_data, ctrl, case_name) {
  
  # Lista completa de algoritmos a probar
  # IMPORTANTE: Se pueden añadir o quitar modelos aquí según disponibilidad
  methods <- c("glm", "rf", "svmRadial", "gbm", "rpart", "knn")
  results_df <- data.frame()
  
  for(m in methods) {
    set.seed(123)
    
    # Entrenamiento con manejo de errores (tryCatch)
    fit <- tryCatch({
      if(m == "gbm") {
        train(Status ~ ., data = train_data, method = m, metric="ROC", 
              trControl = ctrl, preProcess = c("center", "scale", "nzv"), verbose=FALSE)
      } else {
        train(Status ~ ., data = train_data, method = m, metric="ROC", 
              trControl = ctrl, preProcess = c("center", "scale", "nzv"))
      }
    }, error = function(e) return(NULL))
    
    # Evaluación
    if(!is.null(fit)) {
      probs <- predict(fit, valid_data, type = "prob")
      classes <- predict(fit, valid_data)
      cm <- confusionMatrix(classes, valid_data$Status, mode = "everything")
      
      pass_col <- if("Pass" %in% colnames(probs)) "Pass" else colnames(probs)[2]
      roc_obj <- roc(valid_data$Status, probs[, pass_col], levels = c("Fail", "Pass"), direction = "<", quiet=TRUE)
      
      # Guardamos resultados (CON Sensibilidad y Especificidad, SIN Exactitud)
      results_df <- rbind(results_df, data.frame(
        Caso = case_name,
        Modelo = m,
        AUC = as.numeric(auc(roc_obj)),
        Sensibilidad = cm$byClass['Sensitivity'], # Detectar Fallos
        Especificidad = cm$byClass['Specificity'] # Detectar Aprobados
      ))
    }
  }
  return(results_df)
}

```

Caso 1: Todas las Variables / Sin Balanceo

Condiciones: Se utilizan las 30 variables disponibles sin aplicar técnicas de re-muestreo.

```{r}
# Configuración: Sin Balanceo
ctrl_imb <- trainControl(method = "cv", number = 10, classProbs = TRUE, summaryFunction = twoClassSummary)

# Ejecución Completa
results_c1 <- train_and_evaluate_all(train_global, valid_global, ctrl_imb, "Caso 1")
```

Caso 2: Todas las Variables / Con Balanceo (SMOTE)

Condiciones: Se utilizan todas las variables, pero se activa el método SMOTE para equilibrar las clases sintéticamente durante el entrenamiento.

```{r}
# Configuración: Con Balanceo (SMOTE)
ctrl_bal <- trainControl(method = "cv", number = 10, classProbs = TRUE, 
                         summaryFunction = twoClassSummary, sampling = "smote") 

# Ejecución Completa
results_c2 <- train_and_evaluate_all(train_global, valid_global, ctrl_bal, "Caso 2")
```

Caso 3: Variables Seleccionadas / Sin Balanceo

Condiciones: Se filtra el dataset para usar solo las 7 variables más relevantes (failures, absences, etc.), sin balanceo.

```{r}
# Filtrar Datos
train_sel <- train_global[, sel_vars]
valid_sel <- valid_global[, sel_vars]

# Ejecución Completa
results_c3 <- train_and_evaluate_all(train_sel, valid_sel, ctrl_imb, "Caso 3")

```

Caso 4: Variables Seleccionadas / Con Balanceo (SMOTE)

Condiciones: Modelo optimizado. Variables seleccionadas + SMOTE.

```{r}
# Ejecución Completa (usando el control balanceado definido en Caso 2)
results_c4 <- train_and_evaluate_all(train_sel, valid_sel, ctrl_bal, "Caso 4")

```

4.  Comparación Final de Resultados

Se consolida la información de todos los casos para identificar la configuración óptima.

```{r}
# Unir todos los resultados de los 4 casos
final_results <- rbind(results_c1, results_c2, results_c3, results_c4)

# Formatear números para presentación
final_results$AUC <- round(final_results$AUC, 3)
final_results$Sensibilidad <- round(final_results$Sensibilidad, 3)
final_results$Especificidad <- round(final_results$Especificidad, 3)

# Ordenamiento Lógico: Primero por Caso (1, 2, 3, 4), luego por AUC descendente dentro de cada caso
final_results <- final_results %>%
  arrange(Caso, desc(AUC))

# Tabla Estilizada con TODOS los modelos y casos (Sin Exactitud)
kbl(final_results, caption = "Tabla General de Resultados: Comparativa Completa por Caso") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F) %>%
  row_spec(0, bold = T, color = "white", background = "#2c3e50") %>%
  column_spec(4, bold = T, color = "#e74c3c") %>% # Resaltar Sensibilidad
  collapse_rows(columns = 1, valign = "top") # Agrupar visualmente por columna 'Caso'
```

# Conclusiones y Recomendaciones Finales

7.1 Hallazgos Clave del Estudio Selección de Variables es Efectiva: Reducir de 30 a 7 variables mejora la eficiencia sin sacrificar rendimiento

Balanceo Mejora Detección de Riesgo: El sobremuestreo incrementa significativamente la sensibilidad

No Hay un Modelo Único Óptimo: Diferentes configuraciones optimizan diferentes métricas

Variables Críticas Identificadas: Fallas previas, ausencias y aspiración educativa son predictores clave

## Recomendaciones de Implementación

Para Prioridad: Detección Temprana de Riesgo Configuración recomendada: Caso 4 con modelo KNN

Ventaja: 65.62% sensibilidad para detectar estudiantes reprobados

Uso: Sistema de alerta temprana

Para Prioridad: Optimización de Recursos Configuración recomendada: Caso 3 con Regresión Logística

Ventaja: 89.39% especificidad para minimizar falsos positivos

Uso: Asignación dirigida de recursos de apoyo

Para Prioridad: Balance General Configuración recomendada: Caso 2 con Random Forest

Ventaja: Buen balance entre todas las métricas

Uso: Monitoreo general institucional

## Recomendación Final

Basado en el análisis completo, recomendamos una implementación por fases:

Fase 1 (Semanas 1-6): Implementar Caso 4 con KNN para maximizar detección temprana de estudiantes en riesgo.

Fase 2 (Meses 2-6): Añadir Caso 3 con Regresión Logística como verificación secundaria para optimización de recursos.

Fase 3 (Meses 6-12): Desarrollar un sistema ensemble que combine ambas configuraciones, ajustando automáticamente según prioridades institucionales.

## Limitaciones y Trabajo Futuro

Limitaciones Reconocidas: Rendimiento Predictivo Moderado: AUC máximo de 0.6536 indica margen de mejora

Contexto Específico: Datos de sistema educativo portugués

Datos Auto-reportados: Posible sesgo en respuestas

Direcciones Futuras: Integración de Datos Temporales: Seguimiento longitudinal de estudiantes

Validación Cruzada Institucional: Probar en diferentes contextos educativos

Modelos de Explicabilidad: Mejorar interpretabilidad para stakeholders no técnicos

Sistemas de Recomendación: Sugerir intervenciones específicas basadas en perfiles de riesgo

Nota Final: Este estudio demuestra que, aunque la predicción perfecta del rendimiento estudiantil sigue siendo un desafío, es posible identificar factores clave y desarrollar herramientas útiles para la toma de decisiones educativas basadas en datos. La combinación de selección inteligente de variables y técnicas apropiadas de balanceo puede proporcionar insights valiosos para mejorar los resultados estudiantiles.
